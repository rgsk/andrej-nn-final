{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = [chr(i) for i in range(97, 97 + 26)]\n",
    "stoi = {s: i + 1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "  \n",
    "  print(w)\n",
    "  context = [0] * block_size\n",
    "  for ch in w + '.':\n",
    "    ix = stoi[ch]\n",
    "    X.append(context)\n",
    "    Y.append(ix)\n",
    "    print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "    context = context[1:] + [ix] # crop and append\n",
    "  \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27, 2), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5674, -0.2373],\n",
       "        [-0.0274, -1.1008],\n",
       "        [ 0.2859, -0.0296],\n",
       "        [-1.5471,  0.6049],\n",
       "        [ 0.0791,  0.9046],\n",
       "        [-0.4713,  0.7868],\n",
       "        [-0.3284, -0.4330],\n",
       "        [ 1.3729,  2.9334],\n",
       "        [ 1.5618, -1.6261],\n",
       "        [ 0.6772, -0.8404],\n",
       "        [ 0.9849, -0.1484],\n",
       "        [-1.4795,  0.4483],\n",
       "        [-0.0707,  2.4968],\n",
       "        [ 2.4448, -0.6701],\n",
       "        [-1.2199,  0.3031],\n",
       "        [-1.0725,  0.7276],\n",
       "        [ 0.0511,  1.3095],\n",
       "        [-0.8022, -0.8504],\n",
       "        [-1.8068,  1.2523],\n",
       "        [ 0.1476, -1.0006],\n",
       "        [-0.5030, -1.0660],\n",
       "        [ 0.8480,  2.0275],\n",
       "        [-0.1158, -1.2078],\n",
       "        [-1.0406, -1.5367],\n",
       "        [-0.5132,  0.2961],\n",
       "        [-1.4904, -0.2838],\n",
       "        [ 0.2569,  0.2130]])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4713,  0.7868])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4713,  0.7868])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373],\n",
       "         [-0.4713,  0.7868]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [-0.4713,  0.7868],\n",
       "         [ 2.4448, -0.6701]],\n",
       "\n",
       "        [[-0.4713,  0.7868],\n",
       "         [ 2.4448, -0.6701],\n",
       "         [ 2.4448, -0.6701]],\n",
       "\n",
       "        [[ 2.4448, -0.6701],\n",
       "         [ 2.4448, -0.6701],\n",
       "         [-0.0274, -1.1008]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373],\n",
       "         [-1.0725,  0.7276]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [-1.0725,  0.7276],\n",
       "         [-0.0707,  2.4968]],\n",
       "\n",
       "        [[-1.0725,  0.7276],\n",
       "         [-0.0707,  2.4968],\n",
       "         [ 0.6772, -0.8404]],\n",
       "\n",
       "        [[-0.0707,  2.4968],\n",
       "         [ 0.6772, -0.8404],\n",
       "         [-0.1158, -1.2078]],\n",
       "\n",
       "        [[ 0.6772, -0.8404],\n",
       "         [-0.1158, -1.2078],\n",
       "         [ 0.6772, -0.8404]],\n",
       "\n",
       "        [[-0.1158, -1.2078],\n",
       "         [ 0.6772, -0.8404],\n",
       "         [-0.0274, -1.1008]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373],\n",
       "         [-0.0274, -1.1008]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [-0.0274, -1.1008],\n",
       "         [-0.1158, -1.2078]],\n",
       "\n",
       "        [[-0.0274, -1.1008],\n",
       "         [-0.1158, -1.2078],\n",
       "         [-0.0274, -1.1008]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373],\n",
       "         [ 0.6772, -0.8404]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 0.6772, -0.8404],\n",
       "         [ 0.1476, -1.0006]],\n",
       "\n",
       "        [[ 0.6772, -0.8404],\n",
       "         [ 0.1476, -1.0006],\n",
       "         [-0.0274, -1.1008]],\n",
       "\n",
       "        [[ 0.1476, -1.0006],\n",
       "         [-0.0274, -1.1008],\n",
       "         [ 0.2859, -0.0296]],\n",
       "\n",
       "        [[-0.0274, -1.1008],\n",
       "         [ 0.2859, -0.0296],\n",
       "         [-0.4713,  0.7868]],\n",
       "\n",
       "        [[ 0.2859, -0.0296],\n",
       "         [-0.4713,  0.7868],\n",
       "         [-0.0707,  2.4968]],\n",
       "\n",
       "        [[-0.4713,  0.7868],\n",
       "         [-0.0707,  2.4968],\n",
       "         [-0.0707,  2.4968]],\n",
       "\n",
       "        [[-0.0707,  2.4968],\n",
       "         [-0.0707,  2.4968],\n",
       "         [-0.0274, -1.1008]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 1.5674, -0.2373],\n",
       "         [ 0.1476, -1.0006]],\n",
       "\n",
       "        [[ 1.5674, -0.2373],\n",
       "         [ 0.1476, -1.0006],\n",
       "         [-1.0725,  0.7276]],\n",
       "\n",
       "        [[ 0.1476, -1.0006],\n",
       "         [-1.0725,  0.7276],\n",
       "         [ 0.0511,  1.3095]],\n",
       "\n",
       "        [[-1.0725,  0.7276],\n",
       "         [ 0.0511,  1.3095],\n",
       "         [ 1.5618, -1.6261]],\n",
       "\n",
       "        [[ 0.0511,  1.3095],\n",
       "         [ 1.5618, -1.6261],\n",
       "         [ 0.6772, -0.8404]],\n",
       "\n",
       "        [[ 1.5618, -1.6261],\n",
       "         [ 0.6772, -0.8404],\n",
       "         [-0.0274, -1.1008]]])"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9348,  1.0000,  0.9258,  ...,  0.9786, -0.1926,  0.9515],\n",
       "        [ 0.2797,  0.9997,  0.7675,  ...,  0.9929,  0.9992,  0.9981],\n",
       "        [-0.9960,  1.0000, -0.8694,  ..., -0.5159, -1.0000, -0.0069],\n",
       "        ...,\n",
       "        [-0.9996,  1.0000, -0.9273,  ..., -0.9999, -0.9974, -0.9970],\n",
       "        [-0.9043,  1.0000,  0.9868,  ..., -0.7859, -0.4819,  0.9981],\n",
       "        [-0.9048,  1.0000,  0.9553,  ...,  0.9866,  1.0000,  0.9907]])"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0191e+00, -5.0126e-01,  1.3371e+01, -1.3467e+00, -4.9756e+00,\n",
       "         -9.9992e+00, -1.9701e+01,  1.0128e+01,  2.6051e+00,  1.9866e+01,\n",
       "          2.1664e+01, -4.1630e+00, -6.2530e-01, -5.7732e-01,  1.2552e+01,\n",
       "         -1.1293e+00,  2.3699e+00,  5.7146e+00,  6.7237e+00,  2.0819e+00,\n",
       "         -2.7059e+00,  2.2633e+00, -4.2412e+00, -2.8045e+00,  1.0247e+01,\n",
       "          2.8311e+00,  9.2402e+00],\n",
       "        [-6.9784e+00,  8.3823e-01,  9.4671e+00, -1.1949e+00,  7.0614e+00,\n",
       "          9.3584e-01, -6.3802e+00,  1.1896e+01,  1.3653e+01, -1.6366e+00,\n",
       "          2.6264e+01,  2.5903e+00, -2.4583e+00, -1.1175e+00,  1.2883e+01,\n",
       "          2.3099e-02,  8.1749e+00,  3.2475e+00,  8.1620e+00,  9.2478e+00,\n",
       "         -5.2149e+00, -1.0714e+01, -1.6384e+01, -2.3681e+00,  5.7656e+00,\n",
       "          4.1368e+00,  1.2497e+01],\n",
       "        [ 4.1821e+00, -3.6009e+00,  1.7097e+01,  1.2406e+00, -5.6116e+00,\n",
       "         -2.4239e-01, -4.6956e+00, -1.1157e+01, -9.5652e+00,  2.5903e+01,\n",
       "          1.4100e+01,  1.0274e+01,  3.2740e+00,  8.1576e+00, -6.8640e+00,\n",
       "         -4.3681e-01, -1.2461e+01, -9.0634e+00,  1.1423e+00, -1.3093e+01,\n",
       "         -7.7413e+00, -8.1868e+00, -1.9411e+00,  1.2319e+01,  6.5224e+00,\n",
       "         -1.0434e+01, -1.5205e+00],\n",
       "        [ 9.5991e+00, -1.3366e+00,  1.2685e+01, -2.0611e+00, -1.4799e+01,\n",
       "         -6.8374e+00, -4.3772e+00,  2.1818e+00,  1.3250e+01,  1.4994e+01,\n",
       "          5.3153e+00,  2.9902e+00, -7.4475e+00,  5.8099e+00,  2.0527e+01,\n",
       "         -1.2282e+01,  3.4945e+00,  1.1538e+01,  3.6668e+00,  3.4746e+00,\n",
       "         -2.6966e+00,  1.3806e+01,  4.5955e+00, -1.9863e+01,  3.9650e+00,\n",
       "          1.2085e+01,  1.1397e+00],\n",
       "        [-6.1234e+00,  1.7449e-01,  1.6693e+01, -4.9796e+00, -1.4006e+00,\n",
       "         -1.0171e+01, -9.2067e+00,  1.1344e+01,  1.2509e+00,  1.0460e+01,\n",
       "          1.9723e+01, -5.5455e+00,  5.2645e+00,  2.3813e-01,  9.3300e+00,\n",
       "          1.2038e+01,  1.0474e+01,  2.1120e-01,  3.8947e+00,  9.2727e+00,\n",
       "          3.0924e+00,  6.3408e+00, -4.2878e+00, -6.9385e+00,  1.5465e+00,\n",
       "         -1.9308e-01,  2.5513e+00],\n",
       "        [ 2.0191e+00, -5.0126e-01,  1.3371e+01, -1.3467e+00, -4.9756e+00,\n",
       "         -9.9992e+00, -1.9701e+01,  1.0128e+01,  2.6051e+00,  1.9866e+01,\n",
       "          2.1664e+01, -4.1630e+00, -6.2530e-01, -5.7732e-01,  1.2552e+01,\n",
       "         -1.1293e+00,  2.3699e+00,  5.7146e+00,  6.7237e+00,  2.0819e+00,\n",
       "         -2.7059e+00,  2.2633e+00, -4.2412e+00, -2.8045e+00,  1.0247e+01,\n",
       "          2.8311e+00,  9.2402e+00],\n",
       "        [-8.9370e+00,  1.3824e+00,  8.1035e+00, -1.4001e+00,  9.0983e+00,\n",
       "          6.6498e+00, -3.9068e+00,  1.0797e+01,  1.1052e+01, -4.7374e+00,\n",
       "          2.7888e+01,  7.7903e-01, -3.7162e+00,  1.4148e+00,  1.2127e+01,\n",
       "          2.2612e+00,  8.2834e+00,  3.0539e+00,  7.9661e+00,  1.1298e+01,\n",
       "         -4.5582e+00, -9.4655e+00, -1.5756e+01, -2.8853e+00,  8.2799e-01,\n",
       "          6.2631e+00,  1.0490e+01],\n",
       "        [-1.1817e+01, -5.6194e+00,  9.7936e+00,  1.6458e+00,  2.4307e+00,\n",
       "         -9.4741e+00, -2.9384e+00, -1.4284e+01, -2.0933e+00,  2.1132e-01,\n",
       "          1.5972e+01,  3.3184e-01, -1.4865e+00, -1.9170e+01, -1.3810e+00,\n",
       "          4.3827e+00, -1.0027e+01, -1.0918e+01,  1.0928e+00, -5.6071e+00,\n",
       "         -8.8673e+00, -9.4341e+00, -1.0973e+01,  1.4344e+01,  8.6348e+00,\n",
       "         -3.8936e+00,  1.8431e+01],\n",
       "        [ 1.2624e+01, -9.2176e+00,  4.9829e+00, -4.5836e+00, -1.7963e+00,\n",
       "          2.4885e+00, -7.3120e+00, -1.1137e+01, -1.7446e+01,  1.7886e+01,\n",
       "          1.2009e+01,  6.7439e+00, -7.3952e+00, -2.0052e+00, -1.9199e+01,\n",
       "          1.5631e-02, -2.0987e+01, -6.4188e+00, -1.4540e+00, -5.4903e+00,\n",
       "          8.8097e+00,  4.9785e+00, -2.3512e+00,  9.0939e+00,  1.0737e+00,\n",
       "         -7.7066e+00, -2.0273e+01],\n",
       "        [ 1.0859e+01, -7.4450e+00, -1.0873e+00, -7.5913e+00, -2.7330e+00,\n",
       "         -3.2879e+00,  6.1865e+00,  5.3537e+00, -2.0804e+00,  6.4487e+00,\n",
       "          4.5510e+00,  4.2423e+00, -9.1421e+00,  2.5082e+00,  5.2538e+00,\n",
       "         -6.9127e+00, -1.7458e+00,  6.1663e+00,  8.0054e+00,  3.9826e+00,\n",
       "          8.5080e+00,  1.2307e+01,  8.5053e+00, -1.8790e+01,  1.3896e+00,\n",
       "         -2.3486e+00, -5.6214e+00],\n",
       "        [-2.0585e+00, -2.9289e-01,  1.6317e+01, -2.9188e+00, -1.0032e+01,\n",
       "         -1.5058e+00, -5.3732e+00,  6.1772e+00,  2.3989e+00,  1.0712e+01,\n",
       "          1.4178e+01,  3.2862e+00,  1.2259e+00, -7.6503e-01,  1.2031e+01,\n",
       "          2.7236e+00,  8.2598e+00,  1.5393e+00,  6.9128e+00, -1.3188e+01,\n",
       "         -3.3683e+00, -4.3266e+00,  5.5805e+00, -5.8767e+00, -5.7985e+00,\n",
       "          1.6945e-01,  4.5188e-01],\n",
       "        [ 7.1818e+00,  2.4636e+00,  1.1066e+01, -5.3251e+00, -5.6802e+00,\n",
       "         -7.7864e+00, -4.2999e+00,  3.4041e+00,  6.7877e+00,  1.0878e+01,\n",
       "          1.3007e+01,  1.1744e+00, -2.0532e+00, -9.7891e-01,  1.4782e+01,\n",
       "          7.5661e+00,  1.2179e+01,  2.6227e+00, -5.7852e-01, -1.2719e+01,\n",
       "          4.4919e+00, -5.6952e+00,  1.3206e+01, -1.0094e+01, -1.4239e+01,\n",
       "          1.2098e+01, -6.3208e+00],\n",
       "        [ 2.0191e+00, -5.0126e-01,  1.3371e+01, -1.3467e+00, -4.9756e+00,\n",
       "         -9.9992e+00, -1.9701e+01,  1.0128e+01,  2.6051e+00,  1.9866e+01,\n",
       "          2.1664e+01, -4.1630e+00, -6.2530e-01, -5.7732e-01,  1.2552e+01,\n",
       "         -1.1293e+00,  2.3699e+00,  5.7146e+00,  6.7237e+00,  2.0819e+00,\n",
       "         -2.7059e+00,  2.2633e+00, -4.2412e+00, -2.8045e+00,  1.0247e+01,\n",
       "          2.8311e+00,  9.2402e+00],\n",
       "        [-2.7953e+00,  1.0543e+00,  1.6750e+01, -6.4720e+00, -4.9854e+00,\n",
       "         -1.2413e+01, -1.0178e+01,  8.0705e+00,  1.2571e+00,  1.5309e+01,\n",
       "          2.0785e+01, -5.2259e+00,  4.1143e+00, -1.0105e+00,  5.1070e+00,\n",
       "          1.1760e+01,  7.2147e+00,  2.5987e+00,  3.1407e+00,  4.4347e+00,\n",
       "          3.0732e+00,  6.3811e+00, -3.2485e+00, -7.5442e+00, -1.5528e+00,\n",
       "         -1.7122e+00,  5.5256e-01],\n",
       "        [-2.1286e+00,  7.1962e-01,  9.0997e+00, -8.4495e+00, -7.0638e+00,\n",
       "         -5.7193e+00, -5.9840e+00,  8.9019e+00,  3.3309e+00,  5.5097e+00,\n",
       "          1.4994e+01,  2.8810e+00,  7.5798e+00, -1.0702e+00,  6.2841e+00,\n",
       "          9.6604e+00,  8.7781e+00,  1.1881e+00,  7.7960e+00, -8.9427e+00,\n",
       "         -2.3885e+00, -1.7748e+00,  2.6227e+00, -7.2192e+00, -5.9441e+00,\n",
       "         -2.1788e+00,  2.3731e+00],\n",
       "        [ 3.4176e+00,  7.4857e-01,  1.1424e+01, -8.6870e+00, -4.8096e+00,\n",
       "         -4.7653e+00, -6.2365e+00,  6.2932e+00,  2.5725e+00,  8.1339e+00,\n",
       "          8.1285e+00,  3.1393e+00, -1.4330e+00, -3.9122e+00,  9.7731e+00,\n",
       "          6.8014e+00,  1.1524e+01,  2.2850e+00, -1.2631e+00, -1.7247e+01,\n",
       "          1.4742e+00, -8.1434e+00,  1.7889e+01, -6.9276e+00, -1.4375e+01,\n",
       "          2.9665e+00, -6.4945e+00],\n",
       "        [ 2.0191e+00, -5.0126e-01,  1.3371e+01, -1.3467e+00, -4.9756e+00,\n",
       "         -9.9992e+00, -1.9701e+01,  1.0128e+01,  2.6051e+00,  1.9866e+01,\n",
       "          2.1664e+01, -4.1630e+00, -6.2530e-01, -5.7732e-01,  1.2552e+01,\n",
       "         -1.1293e+00,  2.3699e+00,  5.7146e+00,  6.7237e+00,  2.0819e+00,\n",
       "         -2.7059e+00,  2.2633e+00, -4.2412e+00, -2.8045e+00,  1.0247e+01,\n",
       "          2.8311e+00,  9.2402e+00],\n",
       "        [-9.1368e-01, -5.7765e-01,  1.4591e+01, -4.5846e+00, -3.7722e+00,\n",
       "         -1.3475e+01, -1.7458e+01,  1.1428e+01,  1.2059e+00,  1.8054e+01,\n",
       "          2.1369e+01, -2.5642e+00,  4.3124e+00,  3.1865e+00,  1.0390e+01,\n",
       "          7.4397e+00,  4.5813e+00,  2.7003e+00,  4.5525e+00,  2.9407e+00,\n",
       "          2.3107e+00,  7.5942e+00, -3.4622e+00, -3.4334e+00,  3.8618e+00,\n",
       "         -3.6573e+00,  3.8557e+00],\n",
       "        [-3.9037e+00, -1.3739e+00,  1.2444e+01, -7.1445e+00, -6.9140e+00,\n",
       "         -7.7602e+00, -1.0034e+01,  9.0338e+00,  4.6044e+00,  8.0470e+00,\n",
       "          1.8621e+01,  7.1643e-01,  5.1999e+00,  8.1062e-01,  1.0555e+01,\n",
       "          7.9690e+00,  9.2424e+00,  4.1263e+00,  7.7837e+00, -3.3937e+00,\n",
       "         -2.5881e+00,  5.5337e-01,  1.5388e+00, -7.7882e+00, -2.7550e+00,\n",
       "         -4.5887e-02,  4.2994e+00],\n",
       "        [ 1.8946e-01, -6.2181e-01,  1.3582e+01, -7.8257e+00, -7.5501e+00,\n",
       "         -6.7884e+00, -5.7661e+00,  4.2887e+00,  4.2229e+00,  1.0350e+01,\n",
       "          1.7235e+01,  3.4738e-01,  1.7546e+00, -1.6156e+00,  9.1403e+00,\n",
       "          7.0638e+00,  9.9913e+00,  4.8361e-01,  4.2891e+00, -1.3512e+01,\n",
       "         -6.5955e-02, -5.3783e+00,  8.7287e+00, -6.6859e+00, -9.8572e+00,\n",
       "          2.3134e+00, -2.3806e+00],\n",
       "        [-4.4739e+00, -8.1686e+00,  9.3053e+00, -9.2622e-01, -3.3451e+00,\n",
       "          2.5872e+00, -1.3572e+00,  6.8020e+00,  4.4979e+00,  5.2195e+00,\n",
       "          1.0718e+01,  4.5734e+00, -4.2503e+00, -6.9121e+00,  1.1101e+01,\n",
       "          3.3625e+00,  1.0195e+01,  2.8018e+00,  3.3571e+00, -6.4099e+00,\n",
       "         -1.1768e+01, -9.7777e+00,  9.9098e+00, -8.0553e+00, -3.4322e+00,\n",
       "          7.7745e+00, -2.3347e+00],\n",
       "        [-3.6397e+00, -1.3338e+01,  4.2904e+00, -2.2194e+00,  1.4073e+00,\n",
       "         -8.1086e-01, -3.3366e+00, -2.6206e+00,  3.9731e+00,  1.3155e-01,\n",
       "          1.7486e+01,  5.3395e+00, -9.0902e+00, -2.9500e+00,  3.6289e+00,\n",
       "          5.3701e+00, -3.9596e-01,  4.7541e+00,  7.0528e-01,  1.3578e+00,\n",
       "         -4.0747e+00, -1.3207e+01,  4.3240e-01, -7.1182e-02, -6.7771e+00,\n",
       "          9.6153e+00, -2.8385e+00],\n",
       "        [-1.3544e+01, -9.5889e+00,  5.9097e+00,  3.6403e+00, -4.0781e+00,\n",
       "         -7.9994e+00, -3.3134e+00, -1.7119e+01, -2.9872e+00, -4.4444e+00,\n",
       "          1.1357e+01,  3.9077e+00, -4.2552e+00, -1.3067e+01, -9.9777e-01,\n",
       "         -1.0085e+00, -1.3643e+01, -1.2920e+01,  5.3340e+00, -4.4589e+00,\n",
       "         -1.0129e+01, -5.7477e+00, -6.0342e+00,  9.5453e+00,  2.0875e+00,\n",
       "          3.2340e-01,  1.5928e+01],\n",
       "        [-1.7003e+00, -1.9119e+01,  7.0206e+00,  7.4501e+00,  3.1474e+00,\n",
       "         -6.4081e+00, -9.1207e+00, -1.7457e+01, -6.3622e+00,  4.4662e+00,\n",
       "          7.7950e+00, -7.4562e+00, -1.0856e+01, -9.9495e+00, -8.4414e+00,\n",
       "         -6.3951e+00, -2.4572e+01, -1.2007e+01,  7.8885e+00,  3.8502e+00,\n",
       "         -7.6727e+00,  1.5722e+00, -9.8631e+00,  1.3660e+01,  2.3966e+00,\n",
       "         -1.4561e+00,  9.7205e+00],\n",
       "        [ 1.0343e+01, -6.8523e+00,  9.7331e+00, -3.0562e+00,  4.0965e+00,\n",
       "         -2.3608e+00, -3.0143e+00, -1.4034e+01, -1.5576e+01,  1.2131e+01,\n",
       "          1.1234e+01,  9.0949e+00, -3.4573e+00,  1.4960e+00, -2.2098e+01,\n",
       "          2.8614e+00, -1.5072e+01, -7.2300e+00,  1.2995e+00,  2.7068e+00,\n",
       "          1.5625e+01,  1.3180e+01, -5.5981e+00,  6.7369e+00, -7.5351e-01,\n",
       "         -1.2359e+01, -1.0275e+01],\n",
       "        [ 2.0191e+00, -5.0126e-01,  1.3371e+01, -1.3467e+00, -4.9756e+00,\n",
       "         -9.9992e+00, -1.9701e+01,  1.0128e+01,  2.6051e+00,  1.9866e+01,\n",
       "          2.1664e+01, -4.1630e+00, -6.2530e-01, -5.7732e-01,  1.2552e+01,\n",
       "         -1.1293e+00,  2.3699e+00,  5.7146e+00,  6.7237e+00,  2.0819e+00,\n",
       "         -2.7059e+00,  2.2633e+00, -4.2412e+00, -2.8045e+00,  1.0247e+01,\n",
       "          2.8311e+00,  9.2402e+00],\n",
       "        [-2.5954e+00,  3.6915e-01,  1.6733e+01, -6.2273e+00, -4.7147e+00,\n",
       "         -1.3136e+01, -1.2337e+01,  9.3687e+00,  1.4801e+00,  1.6171e+01,\n",
       "          2.1079e+01, -4.2503e+00,  4.1837e+00, -8.9479e-02,  6.5978e+00,\n",
       "          1.0863e+01,  6.7110e+00,  2.4768e+00,  3.0285e+00,  3.9788e+00,\n",
       "          2.8409e+00,  6.9149e+00, -3.2580e+00, -6.2268e+00, -4.7608e-01,\n",
       "         -2.4073e+00,  1.4644e+00],\n",
       "        [-1.5790e+01, -1.7176e+00,  4.0539e+00, -4.0805e+00,  8.3666e+00,\n",
       "         -9.0786e-02,  2.4712e+00,  7.3482e+00,  8.8409e+00, -4.1225e+00,\n",
       "          1.4403e+01,  2.6450e-01, -1.5469e+00, -2.4901e+00,  1.3358e+01,\n",
       "          1.2624e+01,  6.6085e+00,  1.7854e+00,  2.1720e+00,  2.8949e+00,\n",
       "         -7.5549e+00, -1.5113e+01, -3.3036e+00, -1.9102e+00, -3.4913e+00,\n",
       "          2.8229e+00,  1.2949e+01],\n",
       "        [-1.1263e+01, -9.2072e+00,  1.0914e+01,  5.8007e+00,  2.6027e+00,\n",
       "         -5.2036e-01, -6.5609e+00, -1.0748e+01, -5.1058e+00,  7.2671e-01,\n",
       "          1.3861e+01,  1.0656e+01, -1.7970e+00, -1.4461e+01, -1.2997e+01,\n",
       "          2.0886e-01, -1.1376e+01, -9.7191e+00,  1.3919e+00, -9.5842e+00,\n",
       "         -1.1532e+01, -9.4539e+00, -4.1404e+00,  1.4709e+01, -3.5804e+00,\n",
       "         -1.1841e+00,  7.0494e+00],\n",
       "        [ 2.0043e+01, -9.4804e+00,  4.6496e+00, -3.9810e+00, -1.6007e+01,\n",
       "          1.6793e-01, -9.7456e+00, -5.2909e+00, -1.3826e+01,  2.3125e+01,\n",
       "          9.6888e+00,  8.5019e+00, -8.0521e+00, -7.6904e-01, -1.3633e+01,\n",
       "         -8.4529e+00, -1.5941e+01, -3.4932e+00, -2.1559e-01, -8.6168e+00,\n",
       "          5.3666e+00,  1.0167e+01,  4.5748e+00,  5.4511e+00,  3.7089e+00,\n",
       "         -8.4624e+00, -1.8860e+01],\n",
       "        [ 1.1290e+01, -4.3640e+00,  5.8676e+00, -9.8427e+00, -9.3236e+00,\n",
       "         -5.6716e+00,  4.7932e+00,  7.6318e+00,  1.5093e+01,  1.0417e+01,\n",
       "          4.1330e+00,  3.5311e+00, -4.0672e+00, -2.6979e+00,  1.5974e+01,\n",
       "         -7.8997e+00,  1.2334e+01,  1.1212e+01,  9.9674e+00,  1.1554e+01,\n",
       "         -3.6218e+00,  5.1821e+00,  4.8602e+00, -2.2068e+01,  4.5017e+00,\n",
       "          1.2521e+01, -1.8279e+00],\n",
       "        [-2.7066e+00, -1.2426e+00,  1.5158e+01, -6.2523e+00, -5.9217e+00,\n",
       "         -4.2486e+00, -8.5049e+00,  5.6823e+00,  2.2351e+00,  1.2293e+01,\n",
       "          2.4171e+01, -4.3378e+00,  3.4499e+00, -1.2485e+00,  7.8039e+00,\n",
       "          9.7684e+00,  1.3248e+01,  9.2008e-01,  4.5756e+00, -7.4554e+00,\n",
       "         -1.3677e+00, -1.9721e-01,  5.8890e-01, -6.6259e+00, -6.5813e+00,\n",
       "          4.1856e+00,  1.4206e+00]])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = counts / counts.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -probs[torch.arange(32), Y].log().mean()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
